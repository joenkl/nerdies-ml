{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadded\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "from __future__ import division # For python 2.*\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "\n",
    "\n",
    "\n",
    "# Data Loading\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "\n",
    "# The test data\n",
    "Xte = np.genfromtxt('data/X_test.txt', delimiter=None)\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y)\n",
    "Xtr, Ytr = ml.shuffleData(Xtr, Ytr)\n",
    "\n",
    "# Taking a subsample of the data so that trains faster.  You should train on whole data for homework and Kaggle.\n",
    "Xt, Yt = Xtr[:], Ytr[:]\n",
    "print (\"loadded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=34, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=16, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "clf1 = RandomForestClassifier(bootstrap=True, max_depth=600, min_samples_leaf=5, min_samples_split = 13, criterion='entropy', n_estimators=500)\n",
    "clf1.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "clf2 = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.05, \n",
    "                                                loss='exponential',\n",
    "                                                min_samples_split=1400, \n",
    "                                                max_depth=100,  \n",
    "                                                max_features = 'log2',\n",
    "                                                min_samples_leaf=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf3 = KNeighborsClassifier(n_neighbors=10, weights='distance', algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=34, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=16, min_samples_split=4,\n",
       "            min...ski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='distance'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft',\n",
       "         weights=[10, 10, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('gb', clf3)], voting='soft', weights=[10,10,1])\n",
    "clf.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93322652726545563"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict_proba(Xtr)[:,1]\n",
    "print(\"Training AUC: \")\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Ytr, pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79642998524400632"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict_proba(Xva)[:,1]\n",
    "print(\"Validation AUC: \")\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(Yva, pred)\n",
    "metrics.auc(fpr1, tpr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
